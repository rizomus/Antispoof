Тестовое задание.

Классификация. Спуфинг лиц.
Цель: обучить модель классификации для задачи face antispoofing, получить максимальные
метрики на тестовых данных. В итоге модель должна разделять изображения на два класса –
реальное лицо и спуффинг.


Исследовались 3 основных подхода:
  1. Файнтюнинг предобученной свёрточной сети.
  2. Извлечение признаков Local binary patterns.
  3. Извлечение признаков связаных с глубиной изображения.
  
Однако ознакомительное изучение и эксперименты с depth map показали, что для эффективного применения данного подхода мне требуется несколько больше ресурсов, чем я имею возможность выделить на выполнение данного задания, поэтому финально задействованы первые два пункта.

<b> 1. FINE-TUNING </b>

В качестве основы использовалась предобученная Mobilenet. На выходе полносвязные слои размером 256, 128 с активацией 'relu' и выходной слой на 2 нейрона с акцивацией 'softmax'. Loss - sparse_categorical_crossentropy.
Хочу отметить, что идея сделать классификатор не на 2 класса (спуф/лайв), а на несколько (например распечатанные изображения, маски, экраны устройств), кажется мне разумной, но в силу ограниченного доступа к GPU исследования были ограничены бинарной классификацией.

Подготовка датасета:

Из 2500 изображений с пометкой 'LIVE' были отобраны 1000 наиболее релевантных. Критерии отсеивания:

	 - Неправильная метка (обложка журнала, кадр из фильма и пр.)
	 - Много фотошопа
	 - Очень низкое разрешение
	 - Плохое качество (выраженные артефакты сжатия)
	 - Солнцезащитные очки
	 - Лицо частично перекрыто рукой, предметом.
	 - Экспрессивное выражение лица 
	 - Закрытые глаза
	 - Краска на лице
	 - Водяные знаки перекрывающие лицо
	 - Сильный поворот головы
	 - Гипертрофированный макияж
	 - Неестественный контраст/яркость
   
100 случайных изображений 'LIVE' и по 10 каждого вида спуфинга пошло в тестовую выборку (т.е. равное количество обоих классов, для более прозрачного отслеживания в какую сторону алгоритм ошибается больше)

Для тренировочной выборки эмпирически подбиралась пропорция live и spoof изображений. Итоговое соотношение: 3/2. Батч формировался с помощью генератора на основе tf.Sequence.

Были подготовлены несколько вариантов изображений.

  1. Кроп лица по координатам бокса с последующим решейпом к (224, 224, 3). В этом случае возможны искажения пропорций, которые теоретически могут быть признаком спуфа.
  2. Тоже что п.1. но кроп изначально квадратный, решейп (224, 224, 3). 
  3. Для некоторых спуфов характерным признаком может быть край листа/телефона. По этому для возможности извлечения информации о фоновом контексте размер бокса удваивался.
  4. Квадратный кроп (225, 225, 3) разрезался на 9 частей (75, 75, 3) - каждому присваивалась метка всего изображения. 
Во всех вариантах использовались изображения в цветовом пространстве: RGB, нормализованные к [-1,1].

Эксперименты показали, что квадратный кроп не даёт заметных улучшений по сравнению с обычным, однако при более детальном исследовании допускаю возможность какого-то профита.

Исследовались различные варианты "глубины" обучения:
  - Только полносвязный блок
  - Все слои
  - 14 последних
  - 7 последних
  
Итоговый выбор - тренировались 14 последних слоёв (баланс между скоростью обучения, и точностью). 

Наблюдалось довольно сильное переобучение, для борьбы с которым был применён метод greed mask.

![greed mask](https://user-images.githubusercontent.com/104506812/214545376-38f58ee0-0cfc-4094-968f-cf8d0777a4e8.png)

Вероятность маскирования задавалась жёстко, либо начиналась с 0-0,1 и постепенно увеличивалась до 0,5-0,7 с различной скоростью. Наиболее стабильные результаты получились при возрастании от 0 до 0,65 в течение всего периода обучения (для финальных моделей как правило - 150 эпох).

Эффект переобучения снизился, однако остался заметным. Кроме greed mask в качестве аугментаций использовался метод flip: с вероятностью 0,5 все изображения в батче отзеркаливались по горизонтали.

[Логи экспериментов](https://wandb.ai/rizomus/projects)

<b> 1. LOCAL BIARY PATTERNS </b>

Для получения признаков на основе локальных паттернов изображения использовался метод local_binary_pattern (реализация из пакета skimage.feature). 

Изображение разбивалось на 9 частей, переводилось в цветовые пространства YCrCb и HSV (всего 6 каналов), для каждого полученного одноканального изображения вычислялись LBP, на основе полученных данных составлялись гистограммы распределений, которые вытягивались в единый вектор. Полученный вектор признаков использовался для обучения классификатора Random forest. Однако более хорошие результаты удалось получить, уменьшая размерность вектора с помощью метода главных компонент, а в качестве классификатора используя перцептрон из нескольких слоёв. 

В данном подходе эксперименты проводились со следующими гиперпараметрами: P - количество соседних точек, R - радиус, N - количество столбцов гистограммы. Итоговые значения: P=8, R=1, N=512. Тенденция показывала, точность растёт с увеличением N, однако большие значения вычислительно сильно затратны.

Более глубокие исследования могут включать в себя альтернативные методы отбора признаков (например Recursive feature elimination), а также иные классификаторы.

<b> 1. ФИНАЛЬНАЯ МОДЕЛЬ </b>

Ответ формируется как усреднённый предикт 4 моделей:

  1. CNN обученная (fine-tune) на "стандартных" кропах лица (224,224,3)
  2. CNN обученная на кропх лица двойного размера (224,224,3)
  3. CNN обученная на сплитах: (9, 75, 75, 3)
  4. Полносвязная сеть обученная на признаках LBP.
  
В качестве метрик использовались:
  - FAR - False Acceptance Rate
  - FRR - False Rejection Rate
  - HTER - Half Total Error Rate
  
На тестовой выборке из представленного датасета:

FAR = 4.5 %, FRR = 0.5 %, HTER = 2.5 %

Для контрольного тестирования использовались данные найденные в открытом доступе [(13 изображений LIVE и 32 SPOOFING)](https://drive.google.com/drive/folders/1EoYpX_VG2Kvr4sJMK-cL8BHWwRGQU5UZ?usp=sharing)

Показатели на контрольном датасете:

FAR = 6,2 %, FRR = 12.5 %, HTER = 9.4 %


Примеры классификаций:

  Распознанные атаки:
  
![Spoof_11_cr](https://user-images.githubusercontent.com/104506812/214570841-7488951e-4147-4111-965a-0fcc848d5501.png)
![Spoof_31_cr](https://user-images.githubusercontent.com/104506812/214570819-4d83dcbb-636c-4136-8360-d2d919b80e36.PNG)
![Spoof_6_cr](https://user-images.githubusercontent.com/104506812/214570835-c2e7114f-9bc9-4c3c-9318-9213a5fe044b.PNG)

  Нераспознанные атаки:
  
![Spoof_29_CR](https://user-images.githubusercontent.com/104506812/214571951-8aa974f3-b514-424a-914f-102700b7907d.png)
![Spoof_2_CR](https://user-images.githubusercontent.com/104506812/214571961-20ce0bdf-cb67-4d9b-9bee-bb3ab6ce472c.png)
![Spoof_22_CR](https://user-images.githubusercontent.com/104506812/214571965-7d333553-d1ae-4b0c-9d41-7cead754549a.png)

  Ошибочное признание атакой:
  
![Live_12_cr](https://user-images.githubusercontent.com/104506812/214572833-02f503ec-50d2-41ef-a05e-cf4e6f093acc.png)
![Live_6_cr](https://user-images.githubusercontent.com/104506812/214572841-cf62ba9b-6458-4be3-893d-76c14130dbd3.png)
![Live_3_cr](https://user-images.githubusercontent.com/104506812/214572857-4f4dc364-2f90-450e-94d9-93578bffe324.png)

  LIVE:

![Live_5_CR](https://user-images.githubusercontent.com/104506812/214573377-078753bc-d805-40c7-971e-b69a84cad0c6.png)
![Live_2_CR](https://user-images.githubusercontent.com/104506812/214573370-32daae0e-38b9-42c5-ab4f-0adda3b55831.png)
![Live_4_CR](https://user-images.githubusercontent.com/104506812/214573373-6e4c3525-3687-445c-ba2a-920c5e6168c7.png)

Итоговая модель реализована в функции spoofing_detector() из prediction.py. В качестве параметров принимает список путей к файлам изображений. Пример в [колабе](https://colab.research.google.com/drive/1WwIQn5b1SVPunfBYx_cKmJhP0GUboy8y?usp=sharing).

Для детекции лиц необходима библиотека <b>mediapipe</b>!

***

В качестве заключения хочу обозначить некоторые потенциальные пути развития данной работы.

  1. Выделение признаков осонванных на глубине изображения (depth map), интересно было бы попробовать архитектуру типа U-net.
  2. Мультиклассификация на LIVE и несколько типов атак. Возможно отдельные алгоритмы для разных типов.
  3. Нейросеть с разнородными признаками на входе.
  4. Более продвинутое ансамблирование, нежели представленное в данной работе усреднение.
  5. Альтернативные предобученные свёрточные модели для извлечения признаков.
  6. Расширение датасета, особенно в части LIVE.
